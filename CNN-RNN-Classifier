import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader,TensorDataset
from tqdm import tqdm
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

Hout=5
num_epochs=50
lr=0.01

### DATA
N,L,Hin = 100,10,2
batch_size=4
num_classes = 2

X = torch.zeros(N,L,Hin)
X[:N//2,:,0] = 60 + torch.rand(N//2,L)*9
X[N//2:,:,0] = 30 + torch.rand(N//2,L)*9
X[:N//2,:,1] = 10 + torch.rand(N//2,L)*9
X[N//2:,:,1] = 80 + torch.rand(N//2,L)*9
X = X/100
y=torch.cat((torch.zeros(N//2),torch.ones(N//2))).long()
X_train,X_test,y_train,y_test = train_test_split(X,y)

train_dataset = TensorDataset(X_train,y_train)
train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)
test_dataset = TensorDataset(X_test,y_test)
test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)

### BACKBONE
model_type = "CNN"  # or "RNN"

if model_type == "RNN":
    backbone = nn.RNN(input_size=Hin, hidden_size=Hout, batch_first=True)
else:
    backbone = nn.Sequential(
        nn.Conv1d(in_channels=Hin, out_channels=Hout, kernel_size=3, padding=1),
        nn.ReLU()
    )

head = nn.Linear(in_features=Hout, out_features=num_classes)
model = nn.ModuleList([backbone, head]).to(device)

if model_type == "CNN":
    X_train = X_train.permute(0, 2, 1)
    X_test = X_test.permute(0, 2, 1)
    train_dataset = TensorDataset(X_train, y_train)
    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)
    test_dataset = TensorDataset(X_test, y_test)
    test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)

### TRAINING
model.train()
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr = lr)

for epoch in tqdm(range(num_epochs)):
    for Xb, yb in train_dataloader:
        Xb, yb = Xb.to(device), yb.to(device)
        if model_type == "RNN":
            out, h = backbone(Xb)
            features = h.squeeze(0)
        else:
            out = backbone(Xb)
            features = out.mean(dim=2)
        logits = head(features)
        loss = loss_fn(logits, yb)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

### TESTING
score,counter=0,0
model.eval()
with torch.no_grad():
    for Xb, yb in tqdm(test_dataloader):
        Xb, yb = Xb.to(device), yb.to(device)
        if model_type == "RNN":
            out, h = backbone(Xb)
            features = h.squeeze(0)
        else:
            out = backbone(Xb)
            features = out.mean(dim=2)
        logits = head(features)
        y_pred = torch.argmax(logits, dim=1)
        print(yb, y_pred)
        score += (yb == y_pred).sum().item()
        counter += len(yb)

print((score/counter)*100)
